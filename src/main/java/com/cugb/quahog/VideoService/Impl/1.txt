import ai.onnxruntime.*;
import org.bytedeco.javacv.Frame;
import org.bytedeco.opencv.opencv_core.Mat;
import java.util.Collections;
import java.util.HashMap;
import java.util.Map;

public class FrameDetection {

    private OrtSession session;
    private int inputWidth;
    private int inputHeight;
    private String inputName;

    public FrameDetection(String modelPath, int inputWidth, int inputHeight, String inputName) throws Exception {
        OrtEnvironment env = OrtEnvironment.getEnvironment();
        this.session = env.createSession(modelPath);
        this.inputWidth = inputWidth;
        this.inputHeight = inputHeight;
        this.inputName = inputName;
    }

    public Mat processFrame(Mat frame) {
        try {
            // 预处理
            Mat preprocessedMat = preprocess(frame);

            // 创建输入张量
            OnnxTensor inputTensor = createInputTensor(preprocessedMat);

            // 创建输入映射
            Map<String, OnnxTensor> inputs = new HashMap<>();
            inputs.put(inputName, inputTensor);

            // 推理
            OrtSession.Result result = session.run(inputs);

            // 后处理
            Map<String, Object> detections = postprocess(result);

            // 绘制与统计
            Mat processedFrame = drawAndCount(frame, detections);

            // 释放输入张量
            inputTensor.close();

            return processedFrame;
        } catch (Exception e) {
            e.printStackTrace();
            return frame; // 返回原始帧，处理失败时
        }
    }

    private Mat preprocess(Mat frame) {
        // 根据模型要求进行预处理
        Mat resized = new Mat();
        opencv_imgproc.resize(frame, resized, new org.bytedeco.opencv.opencv_core.Size(inputWidth, inputHeight));
        return resized;
    }

    private OnnxTensor createInputTensor(Mat preprocessedMat) throws OrtException {
        // 将Mat转换为FloatBuffer
        FloatBuffer inputBuffer = preprocessedMat.createBuffer();
        // 定义输入张量的形状，例如：[batch_size, channels, height, width]
        long[] inputShape = new long[]{1, 3, inputHeight, inputWidth};
        return OnnxTensor.createTensor(session.getEnvironment(), inputBuffer, inputShape);
    }

    private Map<String, Object> postprocess(OrtSession.Result result) {
        Map<String, Object> detections = new HashMap<>();

        // 解析模型输出，获取边界框、置信度、类别ID
        // 示例：假设输出包含边界框、置信度和类别ID的Tensor
        float[][][] boundingBoxes = (float[][][]) result.get(0).getBuffer().asObject(); // 根据模型调整索引
        float[][] confidenceScores = (float[][]) result.get(1).getBuffer().asObject();
        int[][] classIds = (int[][]) result.get(2).getBuffer().asObject();

        detections.put("boundingBoxes", boundingBoxes);
        detections.put("confidenceScores", confidenceScores);
        detections.put("classIds", classIds);

        return detections;
    }

    private Mat drawAndCount(Mat frame, Map<String, Object> detections) {
        float[][][] boundingBoxes = (float[][][]) detections.get("boundingBoxes");
        float[][] confidenceScores = (float[][]) detections.get("confidenceScores");
        int[][] classIds = (int[][]) detections.get("classIds");

        // 统计当前帧中置信度大于0.7的各类别目标的数量
        Map<Integer, Integer> classCounts = new HashMap<>();
        for (int i = 0; i < confidenceScores.length; i++) {
            for (int j = 0; j < confidenceScores[i].length; j++) {
                if (confidenceScores[i][j] > 0.7) {
                    int classId = classIds[i][j];
                    classCounts.put(classId, classCounts.getOrDefault(classId, 0) + 1);
                }
            }
        }

        // 绘制边界框和类别标签、置信度
        for (int i = 0; i < confidenceScores.length; i++) {
            for (int j = 0; j < confidenceScores[i].length; j++) {
                if (confidenceScores[i][j] > 0.7) {
                    float x1 = boundingBoxes[i][j][0];
                    float y1 = boundingBoxes[i][j][1];
                    float x2 = boundingBoxes[i][j][2];
                    float y2 = boundingBoxes[i][j][3];

                    opencv_imgproc.rectangle(frame, new org.bytedeco.opencv.opencv_core.Point(x1, y1), new org.bytedeco.opencv.opencv_core.Point(x2, y2), new Scalar(0, 255, 0), 2);

                    int classId = classIds[i][j];
                    float confidence = confidenceScores[i][j];
                    String label = "Class " + classId + ": " + String.format("%.2f", confidence);
                    opencv_imgproc.putText(frame, label, new org.bytedeco.opencv.opencv_core.Point(x1, y1 - 10), 0, 0.5, new Scalar(0, 0, 255), 1);
                }
            }
        }

        // 在原始Mat帧上绘制类别:数量
        int y = 20;
        for (Map.Entry<Integer, Integer> entry : classCounts.entrySet()) {
            String countLabel = "Class " + entry.getKey() + ": " + entry.getValue();
            opencv_imgproc.putText(frame, countLabel, new org.bytedeco.opencv.opencv_core.Point(10, y), 0, 0.5, new Scalar(255, 0, 0), 1);
            y += 20;
        }

        return frame;
    }
}